2024-12-08 18:00:41,812 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:00:41,819 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:00:41,868 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:00:41,868 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:00:42,345 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:00:44,782 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:00:44,783 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:00:44,784 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:00:44,784 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:00:44,784 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:00:44,785 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:00:44,786 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:16:26,200 - __main__ - INFO - Received task message
2024-12-08 18:16:26,201 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:16:26,201 - __main__ - INFO - Task type: detection
2024-12-08 18:16:26,203 - __main__ - INFO - Task data: {'Data_Processing.py': '\nclass OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n    ', 'Data_Cleaning.py': '\nclass GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n            \nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n\n    ', 'Download_Data.py': "\nclass GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width),                                 (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)  # set the size of the output\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n    "}
2024-12-08 18:16:26,204 - __main__ - INFO - Task job: god_object
2024-12-08 18:16:26,211 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:16:26,212 - __main__ - ERROR - 'list' object has no attribute 'items'
2024-12-08 18:21:11,920 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:21:11,938 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:21:11,986 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:21:11,986 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:21:12,428 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:21:14,859 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:21:14,860 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:21:14,860 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:21:14,860 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:21:14,861 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:21:14,862 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:21:14,862 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:21:14,919 - __main__ - INFO - Received task message
2024-12-08 18:21:14,921 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:21:14,921 - __main__ - INFO - Task type: detection
2024-12-08 18:21:14,922 - __main__ - INFO - Task data: {'Data_Processing.py': '\nclass OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n    ', 'Data_Cleaning.py': '\nclass GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n            \nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n\n    ', 'Download_Data.py': "\nclass GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width),                                 (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)  # set the size of the output\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n    "}
2024-12-08 18:21:14,923 - __main__ - INFO - Task job: god_object
2024-12-08 18:22:14,096 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:22:14,096 - __main__ - ERROR - 
2024-12-08 18:27:54,036 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:27:54,061 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:27:54,115 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:27:54,116 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:27:54,582 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:27:57,034 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:27:57,035 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:27:57,035 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:27:57,036 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:27:57,036 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:27:57,037 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:27:57,037 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:28:27,859 - __main__ - INFO - Received task message
2024-12-08 18:28:27,859 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:28:27,860 - __main__ - INFO - Task type: detection
2024-12-08 18:28:27,860 - __main__ - INFO - Task data: {'Data_Processing.py': '\nclass OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n    ', 'Data_Cleaning.py': '\nclass GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n            \nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n\n    ', 'Download_Data.py': "\nclass GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width),                                 (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)  # set the size of the output\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n    "}
2024-12-08 18:28:27,861 - __main__ - INFO - Task job: god_object
2024-12-08 18:33:51,485 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:33:51,486 - __main__ - ERROR - 
2024-12-08 18:34:11,088 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:34:11,112 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:34:11,165 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:34:11,165 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:34:11,614 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:34:13,919 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:34:13,920 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:34:13,921 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:34:13,921 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:34:13,921 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:34:13,922 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:34:13,922 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:34:17,170 - __main__ - INFO - Received task message
2024-12-08 18:34:17,171 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:34:17,171 - __main__ - INFO - Task type: detection
2024-12-08 18:34:17,172 - __main__ - INFO - Task data: {'Data_Processing.py': '\nclass OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n    ', 'Data_Cleaning.py': '\nclass GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n            \nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n\n    ', 'Download_Data.py': "\nclass GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width),                                 (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)  # set the size of the output\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n    "}
2024-12-08 18:34:17,173 - __main__ - INFO - Task job: god_object
2024-12-08 18:35:59,564 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:35:59,565 - __main__ - ERROR - 
2024-12-08 18:39:59,707 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:39:59,737 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:39:59,793 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:39:59,794 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:40:00,258 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:40:02,822 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:40:02,824 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:40:02,824 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:40:02,824 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:40:02,824 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:40:02,825 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:40:02,825 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:41:29,869 - __main__ - INFO - Received task message
2024-12-08 18:41:29,870 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:41:29,870 - __main__ - INFO - Task type: detection
2024-12-08 18:41:29,871 - __main__ - INFO - Task data: {'Data_Processing.py': 'class OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n', 'Data_Cleaning.py': 'class GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n\nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n', 'Download_Data.py': "class GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width), (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n"}
2024-12-08 18:41:29,873 - __main__ - INFO - Task job: god_object
2024-12-08 18:43:21,299 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:43:21,300 - __main__ - ERROR - 'list' object has no attribute 'items'
2024-12-08 18:43:38,365 - __main__ - INFO - Received task message
2024-12-08 18:43:38,366 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:43:38,367 - __main__ - INFO - Task type: detection
2024-12-08 18:43:38,367 - __main__ - INFO - Task data: {'Data_Processing.py': 'class OrderProcessor:\n    def __init__(self, validator, payment_gateway, notification_service):\n        self.validator = validator\n        self.payment_gateway = payment_gateway\n        self.notification_service = notification_service\n\n    def process_order(self, order):\n        if not self.validator.validate(order):\n            raise ValueError("Order is invalid")\n\n        payment_status = self.payment_gateway.charge(order)\n        if payment_status == "success":\n            self.notification_service.send_confirmation(order)\n        else:\n            self.notification_service.send_failure(order)\n', 'Data_Cleaning.py': 'class GodClass:\n    def __init__(self, config_path: str, db_path: str):\n        # Configuration\n        self.config = self._load_config(config_path)\n\n        # Database connection\n        self.db_path = db_path\n        self.conn = None\n\n        # Data cache\n        self.data_cache = []\n\n        # Logging settings\n        self.log_file = self.config.get("log_file", "app.log")\n        self.log_level = self.config.get("log_level", "INFO")\n\n        # State\n        self.user_is_logged_in = False\n        self.current_user = None\n\n    def _load_config(self, config_path: str):\n        # Load configuration from a JSON file\n        try:\n            with open(config_path, "r") as f:\n                config = json.load(f)\n        except FileNotFoundError:\n            config = {\n                "log_file": "app.log",\n                "log_level": "INFO",\n                "default_admin": "admin",\n                "default_password": "admin123"\n            }\n        return config\n\n    def log(self, message: str, level: str = "INFO"):\n        # Log a message to a file, ignoring log_level thresholds for simplicity\n        with open(self.log_file, "a") as f:\n            f.write(f"[{level}] {message}\\n")\n\n    def connect_db(self):\n        # Connect to the database\n        if self.conn is None:\n            self.conn = sqlite3.connect(self.db_path)\n            self.log("Connected to the database.", "DEBUG")\n\n    def create_tables(self):\n        # Create tables if they don\'t exist\n        self.connect_db()\n        cursor = self.conn.cursor()\n        self.conn.commit()\n        self.log("Tables ensured in database.", "DEBUG")\n\n    def add_user(self, username: str, password: str):\n        # Add a user to the database\n        self.connect_db()\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute("INSERT INTO users (username, password) VALUES (?, ?)", (username, password))\n            self.conn.commit()\n            self.log(f"User added: {username}", "INFO")\n        except sqlite3.IntegrityError:\n            self.log(f"User {username} already exists.", "ERROR")\n\n    def login_user(self, username: str, password: str):\n        # Login a user\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT * FROM users WHERE username = ? AND password = ?", (username, password))\n        user = cursor.fetchone()\n        if user:\n            self.user_is_logged_in = True\n            self.current_user = username\n            self.log(f"User {username} logged in.", "INFO")\n            return True\n        else:\n            self.log(f"Failed login attempt for user {username}.", "WARNING")\n            return False\n\n    def add_item(self, name: str, value: int):\n        # Add an item to the database\n        if not self.user_is_logged_in:\n            self.log("Attempted to add item without being logged in.", "ERROR")\n            return\n\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("INSERT INTO items (name, value) VALUES (?, ?)", (name, value))\n        self.conn.commit()\n        self.log(f"Item added: {name} with value {value}", "INFO")\n\n    def load_data_into_cache(self):\n        # Load all items from the database into memory\n        self.connect_db()\n        cursor = self.conn.cursor()\n        cursor.execute("SELECT name, value FROM items")\n        self.data_cache = cursor.fetchall()\n        self.log("Data loaded into cache.", "DEBUG")\n\n    def process_data(self):\n        # Process data in memory (e.g., sorting by value)\n        if not self.data_cache:\n            self.log("Data cache is empty, cannot process.", "WARNING")\n            return\n        self.data_cache.sort(key=lambda x: x[1])\n        self.log("Data processed (sorted by value).", "INFO")\n\n    def user_interaction(self):\n        # Simulate user interaction via input/output\n        print("Welcome to the GodClass Application!")\n        username = input("Enter username: ")\n        password = input("Enter password: ")\n        if self.login_user(username, password):\n            print("Login successful.")\n            action = input("Do you want to add an item? (y/n): ")\n            if action.lower() == \'y\':\n                name = input("Item name: ")\n                value = int(input("Item value: "))\n                self.add_item(name, value)\n                print("Item added successfully!")\n            else:\n                print("No action taken.")\n        else:\n            print("Login failed. Goodbye.")\n\n    def close(self):\n        # Close the database connection\n        if self.conn:\n            self.conn.close()\n            self.log("Database connection closed.", "DEBUG")\n\nclass StringUtils:\n    @staticmethod\n    def trim(s: str) -> str:\n        return s.strip()\n\n    @staticmethod\n    def to_upper(s: str) -> str:\n        return s.upper()\n\n    @staticmethod\n    def to_lower(s: str) -> str:\n        return s.lower()\n\n    @staticmethod\n    def tokenize(s: str, delimiter: str = " ") -> list:\n        return s.split(delimiter)\n\n    @staticmethod\n    def is_alphanumeric(s: str) -> bool:\n        return s.isalnum()\n', 'Download_Data.py': "class GaTectorDataset(Dataset):\n    def __init__(self, root_dir, mat_file, input_shape, num_classes, train_mode,train):\n        super(GaTectorDataset, self).__init__()\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.train = train\n        self.train_mode=train_mode\n\n        # GOO pickle\n        self.output_size = 64\n        self.input_size = 224\n        self.root_dir = root_dir\n        self.mat_file = mat_file\n        with open(mat_file, 'rb') as f:\n            self.data = pickle.load(f)\n            self.image_num = len(self.data)\n        self.transform = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                                            ])\n\n    def __len__(self):\n        return self.image_num\n\n    def __getitem__(self, index):\n        index = index % self.image_num\n\n        # GOO pickle\n        data = self.data[index]\n        image_path = data['filename']\n        image_path = os.path.join(self.root_dir, image_path)\n        image_path = image_path.replace('\\\\', '/')\n        gt_box_idx = data['gazeIdx']\n        # Goo gt_box\n        if self.train_mode==0:\n            gt_bboxes = np.copy(data['ann']['bboxes'])\n            gt_labels = np.copy(data['ann']['labels'])\n        if self.train_mode==1:\n            gt_bboxes = np.copy(data['ann']['bboxes']) / [640, 480, 640, 480] * [1920, 1080, 1920, 1080]\n            gt_labels = np.copy(data['ann']['labels'])\n\n        gt_labels = gt_labels[..., np.newaxis]\n        bbox = np.append(gt_bboxes, gt_labels, axis=1)\n        box = bbox.astype(np.int32)\n\n        gaze_gt_box = box[gt_box_idx]\n        gaze_gt_box = gaze_gt_box[np.newaxis, :]\n\n        # GOO\n        eye = [float(data['hx']) / 640, float(data['hy']) / 480]\n        gaze = [float(data['gaze_cx']) / 640, float(data['gaze_cy']) / 480]\n        img = Image.open(image_path)\n        img = img.convert('RGB')\n        width, height = img.size\n        gaze_x, gaze_y = gaze\n        eye_x, eye_y = eye\n\n        k = 0.1\n        x_min = (eye_x - 0.15) * width\n        y_min = (eye_y - 0.15) * height\n        x_max = (eye_x + 0.15) * width\n        y_max = (eye_y + 0.15) * height\n        if x_min < 0:\n            x_min = 0\n        if y_min < 0:\n            y_min = 0\n        if x_max < 0:\n            x_max = 0\n        if y_max < 0:\n            y_max = 0\n        x_min -= k * abs(x_max - x_min)\n        y_min -= k * abs(y_max - y_min)\n        x_max += k * abs(x_max - x_min)\n        y_max += k * abs(y_max - y_min)\n        x_min, y_min, x_max, y_max = map(float, [x_min, y_min, x_max, y_max])\n\n        if self.train:\n            # data augmentation\n            # Jitter (expansion-only) bounding box size\n            if np.random.random_sample() <= 0.5:\n                k = np.random.random_sample() * 0.2\n                x_min -= k * abs(x_max - x_min)\n                y_min -= k * abs(y_max - y_min)\n                x_max += k * abs(x_max - x_min)\n                y_max += k * abs(y_max - y_min)\n\n            # Random Crop\n            if np.random.random_sample() <= 0.5:\n                # Calculate the minimum valid range of the crop that doesn't exclude the face and the gaze target\n                crop_x_min = np.min([gaze_x * width, x_min, x_max])\n                crop_y_min = np.min([gaze_y * height, y_min, y_max])\n                crop_x_max = np.max([gaze_x * width, x_min, x_max])\n                crop_y_max = np.max([gaze_y * height, y_min, y_max])\n\n                # Randomly select a random top left corner\n                if crop_x_min >= 0:\n                    crop_x_min = np.random.uniform(0, crop_x_min)\n                if crop_y_min >= 0:\n                    crop_y_min = np.random.uniform(0, crop_y_min)\n\n                # Find the range of valid crop width and height starting from the (crop_x_min, crop_y_min)\n                crop_width_min = crop_x_max - crop_x_min\n                crop_height_min = crop_y_max - crop_y_min\n                crop_width_max = width - crop_x_min\n                crop_height_max = height - crop_y_min\n                # Randomly select a width and a height\n                crop_width = np.random.uniform(crop_width_min, crop_width_max)\n                crop_height = np.random.uniform(crop_height_min, crop_height_max)\n\n                # Crop it\n                img = TF.crop(img, crop_y_min, crop_x_min, crop_height, crop_width)\n\n                # Record the crop's (x, y) offset\n                offset_x, offset_y = crop_x_min, crop_y_min\n\n                # convert coordinates into the cropped frame\n                x_min, y_min, x_max, y_max = x_min - offset_x, y_min - offset_y, x_max - offset_x, y_max - offset_y\n                # if gaze_inside:\n                gaze_x, gaze_y = (gaze_x * width - offset_x) / float(crop_width), (gaze_y * height - offset_y) / float(crop_height)\n\n                width, height = crop_width, crop_height\n\n                box[:, [0, 2]] = box[:, [0, 2]] - crop_x_min\n                box[:, [1, 3]] = box[:, [1, 3]] - crop_y_min\n\n                # operate gt_box\n                gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] - crop_x_min\n                gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] - crop_y_min\n\n            # Random flip\n            if np.random.random_sample() <= 0.5:\n                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n                x_max_2 = width - x_min\n                x_min_2 = width - x_max\n                x_max = x_max_2\n                x_min = x_min_2\n                gaze_x = 1 - gaze_x\n                box[:, [0, 2]] = width - box[:, [2, 0]]\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n            # Random color change\n            if np.random.random_sample() <= 0.5:\n                img = TF.adjust_brightness(img, brightness_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_contrast(img, contrast_factor=np.random.uniform(0.5, 1.5))\n                img = TF.adjust_saturation(img, saturation_factor=np.random.uniform(0, 1.5))\n\n        head_channel = gaze_imutils.get_head_box_channel(x_min, y_min, x_max, y_max, width, height,\n                                                        resolution=self.input_size, coordconv=False).unsqueeze(0)\n\n        # Crop the face\n        face = img.crop((int(x_min), int(y_min), int(x_max), int(y_max)))\n        face = face.resize((self.input_shape), Image.BICUBIC)\n        face = np.transpose(preprocess_input(np.array(face, dtype=np.float32)), (2, 0, 1))\n        face = torch.Tensor(face)\n        face = self.transform(face)\n        img = img.resize((self.input_shape), Image.BICUBIC)\n        img = np.transpose(preprocess_input(np.array(img, dtype=np.float32)), (2, 0, 1))\n        img = torch.Tensor(img)\n        img = self.transform(img)\n\n        # Bbox deal\n        box[:, [0, 2]] = box[:, [0, 2]] * self.input_size / width\n        box[:, [1, 3]] = box[:, [1, 3]] * self.input_size / height\n\n        # operate_gt_box\n        gaze_gt_box[:, [0, 2]] = gaze_gt_box[:, [0, 2]] * self.input_size / width\n        gaze_gt_box[:, [1, 3]] = gaze_gt_box[:, [1, 3]] * self.input_size / height\n\n        box[:, 0:2][box[:, 0:2] < 0] = 0\n        box[:, 2][box[:, 2] > self.input_size] = self.input_size\n        box[:, 3][box[:, 3] > self.input_size] = self.input_size\n        box_w = box[:, 2] - box[:, 0]\n        box_h = box[:, 3] - box[:, 1]\n        box = box[np.logical_and(box_w > 1, box_h > 1)]\n\n        box = np.array(box, dtype=np.float32)\n        if len(box) != 0:\n            box[:, [0, 2]] = box[:, [0, 2]] / self.input_shape[1]\n            box[:, [1, 3]] = box[:, [1, 3]] / self.input_shape[0]\n\n            box[:, 2:4] = box[:, 2:4] - box[:, 0:2]\n            box[:, 0:2] = box[:, 0:2] + box[:, 2:4] / 2\n\n        # generate the heatmap used for deconv prediction\n        gaze_heatmap = torch.zeros(self.output_size, self.output_size)\n        gaze_heatmap = gaze_imutils.draw_labelmap(gaze_heatmap, [gaze_x * self.output_size, gaze_y * self.output_size],\n                                                3,\n                                                type='Gaussian')\n        face = np.array(face, dtype=np.float32)\n        img = np.array(img, dtype=np.float32)\n        head_channel = np.array(head_channel, dtype=np.float32)\n        gaze_heatmap = np.array(gaze_heatmap, dtype=np.float32)\n\n        return img, box, face, head_channel, gaze_heatmap, eye, gaze, gaze_gt_box\n\n    def rand(self, a=0, b=1):\n        return np.random.rand() * (b - a) + a\n"}
2024-12-08 18:43:38,370 - __main__ - INFO - Task job: god_object
2024-12-08 18:45:42,057 - __main__ - ERROR - Error processing task message with correlation ID: 1234
2024-12-08 18:45:42,058 - __main__ - ERROR - 'list' object has no attribute 'items'
2024-12-08 18:51:44,541 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 18:51:44,568 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 18:51:44,623 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:51:44,624 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:51:45,203 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 18:51:48,773 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 18:51:48,775 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 18:51:48,775 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 18:51:48,776 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 18:51:48,776 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 18:51:48,778 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 18:51:48,779 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 18:51:54,946 - __main__ - INFO - Received task message
2024-12-08 18:51:54,947 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 18:51:54,947 - __main__ - INFO - Task type: detection
2024-12-08 18:51:54,947 - __main__ - INFO - Task job: god_object
2024-12-08 18:51:58,401 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 18:51:58,402 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 18:53:47,057 - llm_processor - INFO - Processed result: File: {Data_Cleaning.py}  
Detected: {GodClass}

File: {Data_Cleaning.py}  
Detected: {StringUtils}

File: {Download_Data.py}  
Detected: {GaTectorDataset}
2024-12-08 19:00:50,745 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 19:00:50,768 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 19:00:50,821 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:00:50,822 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:00:51,401 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 19:00:54,496 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 19:00:54,497 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:00:54,498 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 19:00:54,498 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 19:00:54,499 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 19:00:54,499 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 19:00:54,500 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 19:01:12,683 - __main__ - INFO - Received task message
2024-12-08 19:01:12,683 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 19:01:12,684 - __main__ - INFO - Task type: detection
2024-12-08 19:01:12,684 - __main__ - INFO - Task job: god_object
2024-12-08 19:01:12,939 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 19:01:12,940 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 19:09:03,878 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 19:09:03,886 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 19:09:03,939 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:09:03,939 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:09:04,416 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 19:09:06,886 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 19:09:06,887 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:09:06,888 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 19:09:06,888 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 19:09:06,888 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 19:09:06,889 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 19:09:06,889 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 19:09:13,061 - __main__ - INFO - Received task message
2024-12-08 19:09:13,062 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 19:09:13,063 - __main__ - INFO - Task type: detection
2024-12-08 19:09:13,063 - __main__ - INFO - Task job: god_object
2024-12-08 19:09:13,265 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 19:09:13,266 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 19:14:00,041 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 19:14:00,069 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 19:14:00,117 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:14:00,117 - llm_processor - INFO - Loading model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:14:00,558 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 19:14:03,094 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 19:14:03,095 - llm_processor - INFO - Model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:14:03,096 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 19:14:03,096 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 19:14:03,096 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 19:14:03,097 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 19:14:03,098 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 19:14:33,310 - __main__ - INFO - Received task message
2024-12-08 19:14:33,310 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 19:14:33,311 - __main__ - INFO - Task type: detection
2024-12-08 19:14:33,311 - __main__ - INFO - Task job: god_object
2024-12-08 19:14:46,747 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 19:14:46,748 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 19:16:44,507 - llm_processor - INFO - Processed result: File: Data_Cleaning.py
Detected: GodClass

File: Data_Cleaning.py
Detected: GodClass

File: Data_Cleaning.py
Detected: GodClass

File: Data_Cleaning.py
Detected: GodClass

File: Data_Cleaning.py
Detected: GodClass
2024-12-08 19:17:03,992 - __main__ - INFO - Received task message
2024-12-08 19:17:03,993 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 19:17:03,993 - __main__ - INFO - Task type: detection
2024-12-08 19:17:03,994 - __main__ - INFO - Task job: god_object
2024-12-08 19:17:06,863 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 19:17:06,863 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 19:19:52,213 - llm_processor - INFO - Processed result: File: {Data_Cleaning.py}
Detected: {GodClass}

File: {Data_Cleaning.py}
Detected: {StringUtils}

File: {Data_Cleaning.py}
Detected: {StringUtils}

File: {Data_Cleaning.py}
Detected: {StringUtils}

File: {Data_Cleaning.py}
Detected: {StringUtils}

File: {Data_Cleaning.py}
Detected: {StringUtils}

File: {Download_Data.py}
Detected: {GaTectorDataset}
2024-12-08 19:51:59,063 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 19:51:59,087 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 19:51:59,139 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:51:59,140 - llm_processor - INFO - Loading local model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:51:59,596 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 19:52:02,072 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 19:52:02,074 - llm_processor - INFO - Local model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 19:52:02,074 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 19:52:02,075 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 19:52:02,075 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 19:52:02,076 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 19:52:02,077 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 19:52:08,252 - __main__ - INFO - Received task message
2024-12-08 19:52:08,252 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 19:52:08,253 - __main__ - INFO - Task type: detection
2024-12-08 19:52:08,253 - __main__ - INFO - Task job: god_object
2024-12-08 19:52:08,451 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 19:52:08,451 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 19:57:29,877 - llm_processor - INFO - Processed result: File: Data_Cleaning.py  
Detected: GodClass  
Issue: The class takes on multiple unrelated responsibilities, including configuration, database connection, logging, data caching, user management, and UI interaction, violating the Single Responsibility Principle.

File: Data_Cleaning.py  
Detected: StringUtils  
Issue: The class is not flagged as a large class as it is cohesive and single-purpose, focusing on string manipulation operations.

File: Download_Data.py  
Detected: GaTectorDataset  
Issue: The class takes on multiple unrelated responsibilities, including data loading, data augmentation, and image processing, violating the Single Responsibility Principle.
2024-12-08 22:44:10,173 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 22:44:10,200 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 22:44:10,248 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:44:10,248 - llm_processor - INFO - Loading local model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:44:10,787 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 22:44:14,890 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 22:44:14,891 - llm_processor - INFO - Local model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:44:14,891 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 22:44:14,892 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 22:44:14,892 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 22:44:14,899 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 22:44:14,899 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 22:45:16,142 - __main__ - INFO - Received task message
2024-12-08 22:45:16,144 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 22:45:16,145 - __main__ - INFO - Task type: detection
2024-12-08 22:45:16,146 - __main__ - INFO - Task job: long_function
2024-12-08 22:45:16,558 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 22:45:16,558 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 22:51:58,750 - llm_processor - INFO - Processed result: File: OrderProcessing.py  
Detected: OrderProcessor.OrderProcessor.process_order  
Issue: Function spans 35 lines and performs multiple tasks such as validating order items, deducting stock, processing payment, and notifying the customer.

File: UserDataProcessing.py  
Detected: process_user_data  
Issue: Function spans 23 lines and performs multiple tasks such as reading data from a file, validating the data, storing it in a database, and sending confirmation emails.

File: Logging.py  
Detected: log_message  
Issue: Function spans 16 lines and performs multiple tasks such as logging messages at different levels.

File: DatabaseUtils.py  
Detected: connect_to_database  
Issue: Function spans 8 lines and performs a single task of establishing a connection to the database.

File: DatabaseUtils.py  
Detected: add_user_to_database  
Issue: Function spans 12 lines and performs a single task of adding a user to the database.

File: OrderProcessing.py  
Detected: OrderProcessor.OrderProcessor.process_order  
Issue: Function contains deeply nested if-else statements and performs both data cleaning and visualization tasks, which should be separated into smaller functions.

File: UserDataProcessing.py  
Detected: process_user_data  
Issue: Function contains multiple tasks that should be split into
2024-12-08 22:57:43,359 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 22:57:43,367 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 22:57:43,415 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:57:43,415 - llm_processor - INFO - Loading local model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:57:43,885 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 22:57:46,206 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 22:57:46,207 - llm_processor - INFO - Local model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 22:57:46,208 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 22:57:46,208 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 22:57:46,209 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 22:57:46,210 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 22:57:46,211 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 22:57:57,066 - __main__ - INFO - Received task message
2024-12-08 22:57:57,068 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 22:57:57,070 - __main__ - INFO - Task type: detection
2024-12-08 22:57:57,071 - __main__ - INFO - Task job: long_function
2024-12-08 22:57:57,308 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 22:57:57,310 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 23:08:59,298 - llm_processor - INFO - Processed result: File:OrderProcessing.py  
Detected:process_order  
Issue:Performs multiple tasks such as inventory validation, payment processing, and notification sending, and is too long to be easily maintained.

File:UserDataProcessing.py  
Detected:process_user_data  
Issue:Performs multiple tasks such as file reading, data validation, database storage, and email sending, and is too long to be easily maintained.

File:OrderProcessing.py  
Detected:process_order  
Issue:Has complicated logic due to excessive nesting and multiple conditional statements.

File:UserDataProcessing.py  
Detected:process_user_data  
Issue:Has complicated logic due to excessive nesting and multiple conditional statements.

File:OrderProcessing.py  
Detected:process_order  
Issue:Exceeds a reasonable line threshold with more than 30 lines of substantive code.

File:UserDataProcessing.py  
Detected:process_user_data  
Issue:Exceeds a reasonable line threshold with more than 30 lines of substantive code.

File:Logging.py  
Detected:log_message  
Issue:Performs multiple tasks such as logging at different levels and handling unknown log levels, and is too complex to be easily maintained.

File:DatabaseUtils.py  
Detected:connect_to_database  
Issue:Performs multiple tasks such
2024-12-08 23:11:16,236 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-08 23:11:16,260 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-08 23:11:16,313 - llm_processor - INFO - Models directory: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 23:11:16,314 - llm_processor - INFO - Loading local model pipeline: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 23:11:16,790 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2024-12-08 23:11:19,159 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2024-12-08 23:11:19,160 - llm_processor - INFO - Local model pipeline loaded: E:\FYP\codenexus_microservices\codenexus_microservices\llm-service\models\LLAMA-3.1_8_I
2024-12-08 23:11:19,161 - __main__ - INFO - Initializing knowledge base for detection
2024-12-08 23:11:19,161 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-08 23:11:19,161 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-08 23:11:19,162 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-08 23:11:19,163 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-08 23:11:26,736 - __main__ - INFO - Received task message
2024-12-08 23:11:26,736 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-08 23:11:26,736 - __main__ - INFO - Task type: detection
2024-12-08 23:11:26,737 - __main__ - INFO - Task job: long_function
2024-12-08 23:11:26,980 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-08 23:11:26,980 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-08 23:22:46,285 - llm_processor - INFO - Processed result: File:OrderProcessing.py
Detected:process_order
Issue:Performs multiple tasks and is too long to be easily maintained.

File:UserDataProcessing.py
Detected:process_user_data
Issue:Performs multiple tasks and is too long to be easily maintained.

File:OrderProcessing.py
Detected:process_order
Issue:Has complicated logic due to excessive nesting and multiple responsibilities.

File:UserDataProcessing.py
Detected:process_user_data
Issue:Has complicated logic due to excessive nesting and multiple responsibilities.

File:Logging.py
Detected:log_message
Issue:Exceeds a reasonable line threshold and performs multiple unrelated tasks.

File:DatabaseUtils.py
Detected:connect_to_database
Issue:Exceeds a reasonable line threshold and performs multiple unrelated tasks.

File:DatabaseUtils.py
Detected:add_user_to_database
Issue:Exceeds a reasonable line threshold and performs multiple unrelated tasks.

File:OrderProcessing.py
Detected:process_order
Issue:Has multiple responsibilities such as inventory management, payment processing, and notification sending.

File:UserDataProcessing.py
Detected:process_user_data
Issue:Has multiple responsibilities such as data validation, database storage, and email sending.
2024-12-09 13:47:11,442 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 13:47:11,475 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 13:47:11,527 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 13:47:11,527 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 13:47:11,527 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 13:47:11,528 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 13:47:11,528 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 13:47:11,535 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 13:47:11,536 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 13:47:23,734 - __main__ - INFO - Received task message
2024-12-09 13:47:23,735 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:47:23,735 - __main__ - INFO - Task type: detection
2024-12-09 13:47:23,736 - __main__ - INFO - Task job: long_function
2024-12-09 13:47:23,928 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:47:23,928 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:49:12,753 - __main__ - INFO - Received task message
2024-12-09 13:49:12,754 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:49:12,754 - __main__ - INFO - Task type: detection
2024-12-09 13:49:12,755 - __main__ - INFO - Task job: long_function
2024-12-09 13:49:12,757 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:49:12,757 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:49:33,342 - __main__ - INFO - Received task message
2024-12-09 13:49:33,342 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:49:33,343 - __main__ - INFO - Task type: detection
2024-12-09 13:49:33,343 - __main__ - INFO - Task job: long_function
2024-12-09 13:49:33,345 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:49:33,346 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:49:50,522 - __main__ - INFO - Received task message
2024-12-09 13:49:50,523 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:49:50,523 - __main__ - INFO - Task type: detection
2024-12-09 13:49:50,523 - __main__ - INFO - Task job: long_function
2024-12-09 13:49:50,525 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:49:50,525 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:50:39,845 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 13:50:39,873 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 13:50:39,926 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 13:50:39,927 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 13:50:39,927 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 13:50:39,927 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 13:50:39,928 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 13:50:39,929 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 13:50:39,929 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 13:50:48,182 - __main__ - INFO - Received task message
2024-12-09 13:50:48,183 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:50:48,183 - __main__ - INFO - Task type: detection
2024-12-09 13:50:48,183 - __main__ - INFO - Task job: long_function
2024-12-09 13:50:48,252 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:50:48,253 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:52:35,426 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 13:52:35,455 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 13:52:35,504 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 13:52:35,505 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 13:52:35,505 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 13:52:35,505 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 13:52:35,505 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 13:52:35,506 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 13:52:35,507 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 13:52:40,235 - __main__ - INFO - Received task message
2024-12-09 13:52:40,236 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:52:40,236 - __main__ - INFO - Task type: detection
2024-12-09 13:52:40,237 - __main__ - INFO - Task job: long_function
2024-12-09 13:52:40,311 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:52:40,311 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:54:44,274 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 13:54:44,295 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 13:54:44,341 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 13:54:44,342 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 13:54:44,342 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 13:54:44,342 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 13:54:44,342 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 13:54:44,343 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 13:54:44,343 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 13:54:52,097 - __main__ - INFO - Received task message
2024-12-09 13:54:52,097 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:54:52,098 - __main__ - INFO - Task type: detection
2024-12-09 13:54:52,098 - __main__ - INFO - Task job: god_object
2024-12-09 13:54:52,181 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:54:52,182 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:55:44,228 - __main__ - INFO - Received task message
2024-12-09 13:55:44,228 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:55:44,229 - __main__ - INFO - Task type: detection
2024-12-09 13:55:44,229 - __main__ - INFO - Task job: god_object
2024-12-09 13:55:44,240 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:55:44,240 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:57:10,432 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 13:57:10,464 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 13:57:10,510 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 13:57:10,510 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 13:57:10,511 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 13:57:10,511 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 13:57:10,511 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 13:57:10,512 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 13:57:10,513 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 13:57:20,125 - __main__ - INFO - Received task message
2024-12-09 13:57:20,125 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:57:20,126 - __main__ - INFO - Task type: detection
2024-12-09 13:57:20,126 - __main__ - INFO - Task job: god_object
2024-12-09 13:57:20,206 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:57:20,207 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:57:29,282 - llm_processor - INFO - Processed result: File:{Data_Cleaning.py}
Detected:{GodClass}

Explanation:
The GodClass is a large class that takes on multiple unrelated responsibilities such as configuration, database connection, logging, data processing, and user interaction. This class handles more than one clear domain concern, making it a God Object code smell.
2024-12-09 13:57:39,917 - __main__ - INFO - Received task message
2024-12-09 13:57:39,917 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 13:57:39,918 - __main__ - INFO - Task type: detection
2024-12-09 13:57:39,918 - __main__ - INFO - Task job: long_function
2024-12-09 13:57:39,971 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 13:57:39,972 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 13:57:40,218 - llm_processor - INFO - Processed result: File:OrderProcessing.py  
Detected:OrderProcessor.process_order  
Issue:Performs multiple unrelated tasks, including order validation, inventory management, payment processing, notification, and logging.

File:UserDataProcessing.py  
Detected:process_user_data  
Issue:Performs multiple unrelated tasks, including file reading, data validation, database operations, and email sending.
2024-12-09 14:01:44,556 - __main__ - INFO - Received task message
2024-12-09 14:01:44,557 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 14:01:44,564 - __main__ - INFO - Task type: detection
2024-12-09 14:01:44,564 - __main__ - INFO - Task job: god_object
2024-12-09 14:01:44,576 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 14:01:44,577 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 14:01:44,825 - llm_processor - INFO - Processed result: File:{Data_Cleaning.py}
Detected:{GodClass}

Explanation:
The GodClass is a large class that takes on multiple unrelated responsibilities such as configuration, database connection, logging, data processing, and user interaction. This class handles more than one clear domain concern, making it a God Object code smell.
2024-12-09 14:02:02,605 - __main__ - INFO - Getting queue URL for queue: LLMTaskQueue
2024-12-09 14:02:02,613 - __main__ - INFO - Getting queue URL for queue: LLMResponseQueue
2024-12-09 14:02:02,659 - llm_processor - INFO - Loading model pipeline from Hugging Face API: meta-llama/Llama-3.1-70B-Instruct
2024-12-09 14:02:02,660 - llm_processor - INFO - Model Client loaded from Hugging Face Inference API
2024-12-09 14:02:02,660 - __main__ - INFO - Initializing knowledge base for detection
2024-12-09 14:02:02,660 - utils.rag.retrieval - INFO - Initializing knowledge base for detection
2024-12-09 14:02:02,661 - utils.rag.retrieval - INFO - Loading knowledge base from database
2024-12-09 14:02:02,662 - utils.rag.retrieval - INFO - Checking for saved embeddings and model
2024-12-09 14:02:02,662 - utils.rag.retrieval - INFO - Loading embeddings and model from file
2024-12-09 14:02:09,426 - __main__ - INFO - Received task message
2024-12-09 14:02:09,427 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 14:02:09,427 - __main__ - INFO - Task type: detection
2024-12-09 14:02:09,427 - __main__ - INFO - Task job: god_object
2024-12-09 14:02:09,507 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 14:02:09,508 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 14:02:19,651 - llm_processor - INFO - Processed result: File:Data_Cleaning.py  
Detected:GodClass  
Issue:This class handles unrelated responsibilities such as configuration loading, database connection, data caching, logging, user login, item addition, data processing, and user interaction. It is far from cohesive and handles multiple domain concerns, making it a God Object.
2024-12-09 14:02:25,201 - __main__ - INFO - Received task message
2024-12-09 14:02:25,202 - __main__ - INFO - Processing task message with correlation ID: 1234
2024-12-09 14:02:25,203 - __main__ - INFO - Task type: detection
2024-12-09 14:02:25,203 - __main__ - INFO - Task job: long_function
2024-12-09 14:02:25,255 - __main__ - INFO - Generating response for task message with correlation ID: 1234
2024-12-09 14:02:25,256 - llm_processor - INFO - Processing task with LLM model pipeline
2024-12-09 14:02:25,489 - llm_processor - INFO - Processed result: File:OrderProcessing.py  
Detected:OrderProcessor.process_order  
Issue:Performs multiple unrelated tasks, including order validation, inventory management, payment processing, notification, and logging.

File:UserDataProcessing.py  
Detected:process_user_data  
Issue:Performs multiple unrelated tasks, including file reading, data validation, database operations, and email sending.
